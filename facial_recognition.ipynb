{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1p1wjaqpTh_5RHfJu4vUh8JJCdKwYMHCp' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1p1wjaqpTh_5RHfJu4vUh8JJCdKwYMHCp\" -O data && rm -rf /tmp/cookies.txt\n",
    "!unzip -q data && rm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5749\n"
     ]
    }
   ],
   "source": [
    "!ls lfw2/lfw2/Aaron_Eckhart/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lfw2/lfw2/Adam_Sandler/Adam_Sandler_0001.jpg',\n",
       " 'lfw2/lfw2/Adam_Sandler/Adam_Sandler_0002.jpg',\n",
       " 'lfw2/lfw2/Adam_Sandler/Adam_Sandler_0003.jpg',\n",
       " 'lfw2/lfw2/Adam_Sandler/Adam_Sandler_0004.jpg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob('lfw2/lfw2/Adam_Sandler/*.jpg')\n",
    "print(len(files))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import Dropout, Dense, Lambda, Multiply, Subtract, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "data_path = 'lfw2/lfw2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_name(name, index):\n",
    "    return f'{data_path}{name}/{name}_{str(index).rjust(4, \"0\")}.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name1</th>\n",
       "      <th>ID1</th>\n",
       "      <th>Name2</th>\n",
       "      <th>ID2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AJ_Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>Marsha_Thomason</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron_Sorkin</td>\n",
       "      <td>2</td>\n",
       "      <td>Frank_Solich</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abdel_Nasser_Assidi</td>\n",
       "      <td>2</td>\n",
       "      <td>Hilary_McKay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdoulaye_Wade</td>\n",
       "      <td>4</td>\n",
       "      <td>Linda_Dano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdul_Rahman</td>\n",
       "      <td>1</td>\n",
       "      <td>Magui_Serna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>Tom_Vilsack</td>\n",
       "      <td>1</td>\n",
       "      <td>Wayne_Ferreira</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Trisha_Meili</td>\n",
       "      <td>1</td>\n",
       "      <td>Vladimiro_Montesinos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Ty_Votaw</td>\n",
       "      <td>1</td>\n",
       "      <td>Wayne_Allard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Vytas_Danelius</td>\n",
       "      <td>1</td>\n",
       "      <td>Zaini_Abdullah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Wendy_Kennedy</td>\n",
       "      <td>1</td>\n",
       "      <td>Zara_Akhmadova</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name1  ID1                 Name2  ID2\n",
       "0                 AJ_Cook    1       Marsha_Thomason    1\n",
       "1            Aaron_Sorkin    2          Frank_Solich    5\n",
       "2     Abdel_Nasser_Assidi    2          Hilary_McKay    1\n",
       "3          Abdoulaye_Wade    4            Linda_Dano    1\n",
       "4            Abdul_Rahman    1           Magui_Serna    1\n",
       "...                   ...  ...                   ...  ...\n",
       "1038          Tom_Vilsack    1        Wayne_Ferreira    5\n",
       "1039         Trisha_Meili    1  Vladimiro_Montesinos    3\n",
       "1040             Ty_Votaw    1          Wayne_Allard    1\n",
       "1041       Vytas_Danelius    1        Zaini_Abdullah    1\n",
       "1042        Wendy_Kennedy    1        Zara_Akhmadova    1\n",
       "\n",
       "[1043 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('datasplit.xls', f'train_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_part(set_type, part_type):\n",
    "    name1 = 'Name' if part_type == 'same' else 'Name1'\n",
    "    name2 = 'Name' if part_type == 'same' else 'Name2'\n",
    "    \n",
    "    part_meta = pd.read_excel('datasplit.xls', f'{set_type}_{part_type}')\n",
    "    part_data = [], []\n",
    "    for _, row in part_meta.iterrows():\n",
    "        img1_name = get_image_name(row[name1], row['ID1'])\n",
    "        img1 = cv2.imread(img1_name)/255.\n",
    "        part_data[0].append(img1)\n",
    "        img2_name = get_image_name(row[name2], row['ID2'])\n",
    "        img2 = cv2.imread(img2_name)/255.\n",
    "        part_data[1].append(img2)\n",
    "        \n",
    "    return [np.array(data) for data in part_data]\n",
    "\n",
    "def read_dataset(set_type):\n",
    "\n",
    "    same_data = read_dataset_part(set_type, 'same')\n",
    "    diff_data = read_dataset_part(set_type, 'diff')\n",
    "    x_data = [np.concatenate([s, d]) for s, d in zip(same_data, diff_data)]\n",
    "    y_data = np.concatenate([np.zeros(same_data[0].shape[0]), np.ones(diff_data[0].shape[0])])\n",
    "    \n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = read_dataset('train')\n",
    "val_x, val_y = read_dataset('val')\n",
    "test_x, test_y = read_dataset('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = 0\n",
    "\n",
    "def siamese_model(length):\n",
    "    global sm\n",
    "    inp = Input(shape=length)\n",
    "    X = Conv2D(64, 10, activation='relu')(inp)\n",
    "    X = MaxPooling2D(pool_size=2)(X)\n",
    "    X = Conv2D(128, 7, activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=2)(X)\n",
    "    X = Conv2D(128, 4, activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=2)(X)\n",
    "    X = Conv2D(256, 4, activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=2)(X)\n",
    "    X = Conv2D(512, 3, activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=2)(X)\n",
    "    X = Conv2D(256, 3, activation='relu')(X)\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    sm += 1\n",
    "    \n",
    "    return Model(inp, X, name=f'siamese_model_{sm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"siamese_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 241, 241, 64)      19264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 114, 114, 128)     401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 54, 54, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 24, 24, 256)       524544    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 10, 10, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 3, 3, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2304)              0         \n",
      "=================================================================\n",
      "Total params: 3,567,680\n",
      "Trainable params: 3,567,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model(train_x[0].shape[1:]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_siamese_model(image_shape, output_shape=1):\n",
    "    input_1 = Input(shape=image_shape)\n",
    "    input_2 = Input(shape=image_shape)\n",
    "    \n",
    "    \n",
    "    sm = siamese_model(image_shape)\n",
    "\n",
    "    vector_1 = sm(input_1)\n",
    "    \n",
    "    vector_2 = sm(input_2)\n",
    "    \n",
    "    x3 = Subtract()([vector_1, vector_2])\n",
    "    x6 = tf.math.abs(x3)\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([vector_1, vector_1])\n",
    "    x2_ = Multiply()([vector_2, vector_2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([vector_1, vector_2])\n",
    "\n",
    "    conc = Concatenate(axis=-1)([x3,x4,x5,x6])\n",
    "\n",
    "    x = Dense(512, activation=\"relu\")(conc)\n",
    "#     x = Dropout(0.01)(x)\n",
    "    out = Dense(output_shape, activation=\"sigmoid\", name = 'out')(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam())#, metrics=['mse', 'mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    acc = 'val_loss'\n",
    "    acc_mode = 'min'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                              fr'./models/{model_name}.h5', \n",
    "                              monitor=acc, \n",
    "#                               verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              mode=acc_mode)\n",
    "    earlystop = EarlyStopping(monitor=acc, mode=acc_mode, verbose=1, patience=6)\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 5,\n",
    "                            factor = 0.5, min_lr = 1e-6, verbose = 1)\n",
    "\n",
    "    return [checkpoint, reduceLR, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_gen, train_data, val_data, batch_size=16, use_saved=False):\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    model_name = model_gen.__name__[5:]\n",
    "        \n",
    "    if use_saved:\n",
    "        history = joblib.load(fr'./models/{model_name}_history.sav')\n",
    "    else:\n",
    "        callbacks = get_callbacks(model_name)\n",
    "        \n",
    "        train_x, train_y = train_data\n",
    "        model = model_gen(train_x[0].shape[1:])\n",
    "        history = model.fit(\n",
    "                            x=train_x,\n",
    "                            y=train_y,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=20,\n",
    "                            validation_data=val_data,\n",
    "                            callbacks=callbacks\n",
    "                            )\n",
    "        \n",
    "        history = history.history\n",
    "        joblib.dump(history, fr'./models/{model_name}_history.sav')\n",
    "    \n",
    "    model = load_model(fr'./models/{model_name}.h5')\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "66/66 [==============================] - 12s 174ms/step - loss: 0.6987 - val_loss: 0.6932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 11s 161ms/step - loss: 0.6932 - val_loss: 0.6935 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 11s 161ms/step - loss: 0.6932 - val_loss: 0.6932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 11s 165ms/step - loss: 0.6932 - val_loss: 0.6931 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 11s 163ms/step - loss: 0.6932 - val_loss: 0.6934 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "65/66 [============================>.] - ETA: 0s - loss: 0.6933\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "66/66 [==============================] - 11s 162ms/step - loss: 0.6933 - val_loss: 0.6931 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 11s 162ms/step - loss: 0.6933 - val_loss: 0.6932 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 11s 164ms/step - loss: 0.6932 - val_loss: 0.6933 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 11s 162ms/step - loss: 0.6931 - val_loss: 0.6931 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 11s 163ms/step - loss: 0.6934 - val_loss: 0.6935 - lr: 5.0000e-04\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "siam_model, siam_history = train_model(init_siamese_model,\n",
    "                                       (train_x, train_y),\n",
    "                                       (val_x, val_y),\n",
    "                                       batch_size=32,\n",
    "                                       use_saved=False)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_46 (InputLayer)           [(None, 250, 250, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           [(None, 250, 250, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "siamese_model_10 (Model)        (None, 2304)         3567680     input_46[0][0]                   \n",
      "                                                                 input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subtract_24 (Subtract)          (None, 2304)         0           siamese_model_10[1][0]           \n",
      "                                                                 siamese_model_10[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 2304)         0           siamese_model_10[1][0]           \n",
      "                                                                 siamese_model_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 2304)         0           siamese_model_10[2][0]           \n",
      "                                                                 siamese_model_10[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 2304)         0           subtract_24[0][0]                \n",
      "                                                                 subtract_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_25 (Subtract)          (None, 2304)         0           multiply_37[0][0]                \n",
      "                                                                 multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           siamese_model_10[1][0]           \n",
      "                                                                 siamese_model_10[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Abs_5 (TensorFlowOp (None, 2304)         0           subtract_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 6913)         0           multiply_36[0][0]                \n",
      "                                                                 subtract_25[0][0]                \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 tf_op_layer_Abs_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          3539968     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            513         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,108,161\n",
      "Trainable params: 7,108,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
